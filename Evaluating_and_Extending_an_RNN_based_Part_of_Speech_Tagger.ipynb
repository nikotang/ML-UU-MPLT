{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 02 - Evaluating and Extending an RNN based Part-of-Speech Tagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgPqt4p1y36p"
      },
      "source": [
        "# Assignment 2: Evaluating and Extending an RNN based Part-of-Speech Tagger\n",
        "\n",
        "Extensions 1 (GRU), 2 (bidirectional), 3 (`Dataset` and `Dataloader` class) and 8 (universal vs language specific POS tags) are implemented.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before starting\n",
        "\n",
        "Some installations and imports."
      ],
      "metadata": {
        "id": "r2Xd77Bzvdn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvAGiH19cYY0",
        "outputId": "236f9d7f-8dea-43d3-d0e3-d61d6287ba0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting conllu\n",
            "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDDstzhwztQS"
      },
      "source": [
        "# Our standard imports for maths and basic methodology\n",
        "import numpy as np\n",
        "# from sklearn.model_selection import train_test_split \n",
        "\n",
        "# For downloading and parsing the datasets\n",
        "import os\n",
        "from conllu import parse\n",
        "import glob\n",
        "\n",
        "# For user feedback\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# Imports for pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYGiUxG746pz",
        "outputId": "4467e989-da0d-43a8-8f3a-e4eede2455b7"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  for i in range(torch.cuda.device_count()):\n",
        "    print(torch.cuda.get_device_name(i))\n",
        "else:\n",
        "  print(\"No GPU available\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO0m41-MzJRc"
      },
      "source": [
        "## Load and format tagging data\n",
        "\n",
        "The training and test sets of three treebanks are loaded to a newly created directory.\n",
        "\n",
        "Functions are created to extract the sentences and POS tags from the loaded UD data and to show some simple information of the treebanks. \n",
        "\n",
        "Here we pick Vietnamese, English and Finnish as representatives of morphologically poor to morphologically rich languages."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"data\" not in os.listdir():\n",
        "  os.mkdir(\"data\")\n",
        "\n",
        "treebanks = {'UD_English-GUM': ['en_gum-ud-train.conllu', 'en_gum-ud-test.conllu'], \n",
        "             'UD_Finnish-TDT': ['fi_tdt-ud-train.conllu', 'fi_tdt-ud-test.conllu'],\n",
        "             'UD_Vietnamese-VTB': ['vi_vtb-ud-train.conllu', 'vi_vtb-ud-test.conllu'],}\n",
        "for treebank in treebanks:\n",
        "  for dataset in treebanks[treebank]:\n",
        "    url = f\"https://raw.githubusercontent.com/UniversalDependencies/{treebank}/master/{dataset}\"\n",
        "    !wget --no-cache -N -P data {url}\n"
      ],
      "metadata": {
        "id": "PYsPw_HlbOWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58692f8-8ead-4f9b-83c4-c2b1f21d74e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-15 13:01:25--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/master/en_gum-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10998186 (10M) [text/plain]\n",
            "Saving to: ‘data/en_gum-ud-train.conllu’\n",
            "\n",
            "en_gum-ud-train.con 100%[===================>]  10.49M  --.-KB/s    in 0.03s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:25 (310 MB/s) - ‘data/en_gum-ud-train.conllu’ saved [10998186/10998186]\n",
            "\n",
            "--2022-06-15 13:01:26--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/master/en_gum-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1753652 (1.7M) [text/plain]\n",
            "Saving to: ‘data/en_gum-ud-test.conllu’\n",
            "\n",
            "en_gum-ud-test.conl 100%[===================>]   1.67M  --.-KB/s    in 0.01s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:26 (168 MB/s) - ‘data/en_gum-ud-test.conllu’ saved [1753652/1753652]\n",
            "\n",
            "--2022-06-15 13:01:26--  https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13373316 (13M) [text/plain]\n",
            "Saving to: ‘data/fi_tdt-ud-train.conllu’\n",
            "\n",
            "fi_tdt-ud-train.con 100%[===================>]  12.75M  --.-KB/s    in 0.05s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:26 (271 MB/s) - ‘data/fi_tdt-ud-train.conllu’ saved [13373316/13373316]\n",
            "\n",
            "--2022-06-15 13:01:26--  https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1727594 (1.6M) [text/plain]\n",
            "Saving to: ‘data/fi_tdt-ud-test.conllu’\n",
            "\n",
            "fi_tdt-ud-test.conl 100%[===================>]   1.65M  --.-KB/s    in 0.01s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:26 (140 MB/s) - ‘data/fi_tdt-ud-test.conllu’ saved [1727594/1727594]\n",
            "\n",
            "--2022-06-15 13:01:26--  https://raw.githubusercontent.com/UniversalDependencies/UD_Korean-Kaist/master/ko_kaist-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18468775 (18M) [text/plain]\n",
            "Saving to: ‘data/ko_kaist-ud-train.conllu’\n",
            "\n",
            "ko_kaist-ud-train.c 100%[===================>]  17.61M  --.-KB/s    in 0.07s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:27 (248 MB/s) - ‘data/ko_kaist-ud-train.conllu’ saved [18468775/18468775]\n",
            "\n",
            "--2022-06-15 13:01:27--  https://raw.githubusercontent.com/UniversalDependencies/UD_Korean-Kaist/master/ko_kaist-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1778348 (1.7M) [text/plain]\n",
            "Saving to: ‘data/ko_kaist-ud-test.conllu’\n",
            "\n",
            "ko_kaist-ud-test.co 100%[===================>]   1.70M  --.-KB/s    in 0.01s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:27 (155 MB/s) - ‘data/ko_kaist-ud-test.conllu’ saved [1778348/1778348]\n",
            "\n",
            "--2022-06-15 13:01:27--  https://raw.githubusercontent.com/UniversalDependencies/UD_Spanish-AnCora/master/es_ancora-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42516504 (41M) [text/plain]\n",
            "Saving to: ‘data/es_ancora-ud-train.conllu’\n",
            "\n",
            "es_ancora-ud-train. 100%[===================>]  40.55M   196MB/s    in 0.2s    \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:28 (196 MB/s) - ‘data/es_ancora-ud-train.conllu’ saved [42516504/42516504]\n",
            "\n",
            "--2022-06-15 13:01:28--  https://raw.githubusercontent.com/UniversalDependencies/UD_Spanish-AnCora/master/es_ancora-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5077628 (4.8M) [text/plain]\n",
            "Saving to: ‘data/es_ancora-ud-test.conllu’\n",
            "\n",
            "es_ancora-ud-test.c 100%[===================>]   4.84M  --.-KB/s    in 0.02s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:28 (294 MB/s) - ‘data/es_ancora-ud-test.conllu’ saved [5077628/5077628]\n",
            "\n",
            "--2022-06-15 13:01:28--  https://raw.githubusercontent.com/UniversalDependencies/UD_Hindi-HDTB/master/hi_hdtb-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41227906 (39M) [text/plain]\n",
            "Saving to: ‘data/hi_hdtb-ud-train.conllu’\n",
            "\n",
            "hi_hdtb-ud-train.co 100%[===================>]  39.32M   153MB/s    in 0.3s    \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:29 (153 MB/s) - ‘data/hi_hdtb-ud-train.conllu’ saved [41227906/41227906]\n",
            "\n",
            "--2022-06-15 13:01:29--  https://raw.githubusercontent.com/UniversalDependencies/UD_Hindi-HDTB/master/hi_hdtb-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5180998 (4.9M) [text/plain]\n",
            "Saving to: ‘data/hi_hdtb-ud-test.conllu’\n",
            "\n",
            "hi_hdtb-ud-test.con 100%[===================>]   4.94M  --.-KB/s    in 0.03s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:29 (193 MB/s) - ‘data/hi_hdtb-ud-test.conllu’ saved [5180998/5180998]\n",
            "\n",
            "--2022-06-15 13:01:30--  https://raw.githubusercontent.com/UniversalDependencies/UD_Vietnamese-VTB/master/vi_vtb-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 961935 (939K) [text/plain]\n",
            "Saving to: ‘data/vi_vtb-ud-train.conllu’\n",
            "\n",
            "vi_vtb-ud-train.con 100%[===================>] 939.39K  --.-KB/s    in 0.008s  \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:30 (119 MB/s) - ‘data/vi_vtb-ud-train.conllu’ saved [961935/961935]\n",
            "\n",
            "--2022-06-15 13:01:30--  https://raw.githubusercontent.com/UniversalDependencies/UD_Vietnamese-VTB/master/vi_vtb-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 558630 (546K) [text/plain]\n",
            "Saving to: ‘data/vi_vtb-ud-test.conllu’\n",
            "\n",
            "vi_vtb-ud-test.conl 100%[===================>] 545.54K  --.-KB/s    in 0.009s  \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-06-15 13:01:30 (60.8 MB/s) - ‘data/vi_vtb-ud-test.conllu’ saved [558630/558630]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `UDDataset` from the `Dataset` class. The `pad_and_encode` method is moved here to be used in our dataloader."
      ],
      "metadata": {
        "id": "NEZi8Nl01rYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UDDataset(Dataset):\n",
        "  def __init__(self, language_code, train_or_test, pos=\"upos\"):\n",
        "    '''Parses the conllu format and returns lists of sentences and their corresponding POS tags. '''\n",
        "    file_list = glob.glob(f\"./data/{language_code}*{train_or_test}.conllu\")\n",
        "    data = open(file_list[0], mode=\"r\", encoding=\"utf-8\")\n",
        "    annotations = data.read()\n",
        "    sents = parse(annotations)                                                  # list of TokenLists\n",
        "\n",
        "    # iterate through the TokenList format of sentences to get tuples of each word and its POS tag\n",
        "    sentences = []\n",
        "    for sent in sents:\n",
        "      if len(sent) > 2:\n",
        "        sentence = [(word['form'], word[pos]) for word in sent]\n",
        "        sentences.append(sentence)\n",
        "\n",
        "    # put the words in a list and their tags in another\n",
        "    self.X = [[token for token, tag in sentence] for sentence in sentences]\n",
        "    self.y = [[tag for token, tag in sentence] for sentence in sentences]\n",
        "    self.X, self.y = self.X[:10000], self.y[:10000]                             # length capped for our selected treebanks\n",
        " \n",
        "  def __len__(self):\n",
        "    assert len(self.X) == len(self.y)\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def pad_and_encode(self, data):\n",
        "    '''Pads and encodes the sentences and labels. '''\n",
        "    sentences, labels = zip(*data)\n",
        "    assert len(sentences)==len(labels)\n",
        "    assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "    max_sentence_length = np.max([len(sentence) for sentence in sentences]) \n",
        "    padded_sentences = torch.zeros(len(sentences), max_sentence_length,         # Create data structures with <PAD> as default\n",
        "                                  dtype=torch.long)\n",
        "    padded_sentences[:] = token2idx['<PAD>']\n",
        "    padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                                dtype=torch.long)\n",
        "    padded_labels[:] = tag2idx['<PAD>']\n",
        "    for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "      for j, token in enumerate(sentence):\n",
        "        if token in token2idx.keys():\n",
        "          padded_sentences[i, j] = token2idx[token]\n",
        "        else:\n",
        "          padded_sentences[i, j] = token2idx['<UNK>']\n",
        "      for j, tag in enumerate(tags):\n",
        "        if tag in tag2idx.keys():\n",
        "          padded_labels[i, j] = tag2idx[tag]\n",
        "        else:\n",
        "          padded_labels[i, j] = tag2idx['<UNK>']                                # Unseen tags\n",
        "    if torch.cuda.is_available():\n",
        "      return padded_sentences.cuda(), padded_labels.cuda()\n",
        "    return padded_sentences, padded_labels"
      ],
      "metadata": {
        "id": "tXvu5MSNfprB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z25i9_UxtUeR"
      },
      "source": [
        "def inspect(language, X_train, X_test):\n",
        "  ''' Prints the no. of sentences in the datasets and plots their sentence length distribution. '''\n",
        "  print(f\"The training set of {language} includes {len(X_train)} sentences\")\n",
        "  print(f\"The test set of {language} includes {len(X_test)} sentences\")\n",
        "  l = np.asarray([len(x) for x in X_train], dtype=int)\n",
        "  plt.figure(figsize=(8, 4))\n",
        "  x = np.unique(l)\n",
        "  plt.bar(x, [np.sum(l==e) for e in x], width=1)\n",
        "  plt.xlabel(\"Sentence length\")\n",
        "  plt.ylabel(\"# sentences\")\n",
        "  plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHIiYxLyz2cf"
      },
      "source": [
        "## Data encoding and padding\n",
        "\n",
        "Build lookup tables for our tokens and tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fjVkyDOP9MU"
      },
      "source": [
        "def lut(X_train, y_train):\n",
        "  '''Pads the data and returns lookup tables for our tokens and tags. '''\n",
        "  tokens = {token for sentence in X_train for token in sentence}\n",
        "  idx2token = list(tokens)\n",
        "  idx2token.insert(0, '<UNK>')      # deal with OOV words\n",
        "  idx2token.append('<PAD>')\n",
        "  token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "  tags = {tag for tags in y_train for tag in tags}\n",
        "  idx2tag = list(tags)\n",
        "  idx2tag.append('<PAD>')\n",
        "  idx2tag.append('<UNK>')           # account for unseen tags\n",
        "  tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "  return token2idx, tag2idx, idx2token, idx2tag"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmgbWbsJk8DW"
      },
      "source": [
        "## Model\n",
        "\n",
        "Our model is built as the `Tagger` class here. \n",
        "\n",
        "Most of the originaly provided comments are deleted for the purpose of this assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwU6cWT2AqT6"
      },
      "source": [
        "class Tagger(nn.Module):\n",
        "  def __init__(self, word_embedding_dim, hidden_dim, vocabulary_size, tagset_size, lstm_gru='LSTM', bidirectional=True):\n",
        "    \"\"\"A LSTM/GRU based tagger\n",
        "    \n",
        "    word_embedding_dim\n",
        "      The dimensionality of the word embedding\n",
        "    hidden_dim\n",
        "      The dimensionality of the hidden state in the LSTM or GRU\n",
        "    vocabulary_size\n",
        "      The number of unique tokens in the word embedding (including <PAD> etc)\n",
        "    tagset_size\n",
        "      The number of unique POS tags\n",
        "    lstm_gru\n",
        "      The type of model, can take 'LSTM' or 'GRU'\n",
        "    bidirectional\n",
        "      Bidirectionality of the model, Boolean default as True\n",
        "    \"\"\"\n",
        "    super().__init__()            \n",
        "    self.hidden_dim_ = hidden_dim                           \n",
        "    self.vocabulary_size_ = vocabulary_size\n",
        "    self.tagset_size_ = tagset_size\n",
        "    self.batch_size = 256\n",
        "    self.epochs = 5\n",
        "    self._word_embedding = nn.Embedding(num_embeddings=vocabulary_size,         \n",
        "                                         embedding_dim=word_embedding_dim, \n",
        "                                         padding_idx=token2idx['<PAD>'])\n",
        "    self._tagger = getattr(nn, lstm_gru)(input_size=word_embedding_dim,          \n",
        "                         hidden_size=hidden_dim,                           \n",
        "                         batch_first=True, bidirectional=bidirectional)\n",
        "    if bidirectional:\n",
        "      self._fc = nn.Linear(hidden_dim*2, tagset_size)                           # The dimensionality of the hidden state has to double for bidirectionality\n",
        "    else:\n",
        "      self._fc = nn.Linear(hidden_dim, tagset_size)\n",
        "    self._softmax = nn.LogSoftmax(dim=1)                                        \n",
        "    \n",
        "    self.training_loss_ = list()                                                # For plotting\n",
        "    self.training_accuracy_ = list()\n",
        "\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU if available\n",
        "      self.cuda()\n",
        "\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "\n",
        "    embedded_sentences = self._word_embedding(padded_sentences)                    \n",
        "\n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        \n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            \n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    tagger_out, _ = self._tagger(X)                                             # Run the layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(tagger_out, batch_first=True)       # Unpack the output\n",
        "\n",
        "    X = X.contiguous().view(-1, X.shape[2])                                     # Flatten the output\n",
        "    tag_space = self._fc(X)                                                     # Fully connected layer\n",
        "    tag_scores = self._softmax(tag_space)                                       # Apply softmax\n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size_)\n",
        "\n",
        "  def fit(self, dataset):\n",
        "    loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])                                                                                                  \n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=0.01)                                                                                      \n",
        "    for epoch in range(self.epochs):                                            \n",
        "      for inputs, targets in DataLoader(dataset=dataset, batch_size=self.batch_size, \n",
        "                                        shuffle=True, collate_fn=dataset.pad_and_encode):                                            \n",
        "        self.zero_grad()                                                        \n",
        "        scores = self(inputs)                                                   # Forward pass\n",
        "        loss = loss_function(scores.view(-1, self.tagset_size_),              \n",
        "                            targets.view(-1))               \n",
        "        loss.backward()                                                         # Backpropagate the error\n",
        "        optimizer.step()                                                       \n",
        "        predictions = scores.argmax(dim=2, keepdim=True).squeeze()             \n",
        "        mask = targets!=tag2idx['<PAD>']                                         \n",
        "        correct = (predictions[mask] == targets[mask]).sum().item()            \n",
        "        accuracy = correct / mask.sum().item()*100\n",
        "        self.training_accuracy_.append(accuracy)                              \n",
        "        self.training_loss_.append(loss.item())                               \n",
        "\n",
        "  def score(self, dataset):\n",
        "    with torch.no_grad():                                                          \n",
        "      n_correct = 0\n",
        "      n_total = 0\n",
        "      for inputs, targets in DataLoader(dataset=dataset, batch_size=self.batch_size, \n",
        "                                        shuffle=True, collate_fn=dataset.pad_and_encode):\n",
        "        scores = self(inputs)                                                      \n",
        "        predictions = scores.argmax(dim=2, keepdim=True).squeeze()                 \n",
        "        mask = targets!=tag2idx['<PAD>']                                          \n",
        "        n_correct += (predictions[mask] == targets[mask]).sum().item()            \n",
        "        n_total += mask.sum().item()\n",
        "    return 100*n_correct/n_total"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEZlbcallbff"
      },
      "source": [
        "## Run the model on our treebanks\n",
        "\n",
        "The model is first fun on the given model for our baseline accuracy (unidirectional LSTM). Then the model is run on the three treebanks with the settigns of bi-LSTM, and uni- and bi-directional GRU."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "languages = {'vi': 'Vietnamese', 'en': 'English', 'fi': 'Finnish'}\n",
        "binary_features = ['Baseline', 'GRU', 'bi-LSTM', 'bi-GRU']\n",
        "table = {feature: [] for feature in binary_features}\n",
        "\n",
        "for language in languages:\n",
        "  train_dataset = UDDataset(language, 'train')\n",
        "  test_dataset = UDDataset(language, 'test')\n",
        "  for feature in table:\n",
        "    print(f'Modelling {languages[language]} with {feature}...')\n",
        "    rnn_type, bi = 'LSTM', False     # baseline settings\n",
        "    if 'GRU' in feature:\n",
        "      rnn_type = 'GRU'\n",
        "    if 'bi-' in feature:\n",
        "      bi = True\n",
        "\n",
        "    token2idx, tag2idx, idx2token, idx2tag = lut(train_dataset.X, train_dataset.y)\n",
        "    model = Tagger(word_embedding_dim=32,                                               # Dimensionality of the word embedding\n",
        "                      hidden_dim=64,                                                    # Dimensionality of the hidden state in the LSTM/GRU\n",
        "                      vocabulary_size=len(token2idx),                                   # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                      tagset_size=len(tag2idx)-1, lstm_gru=rnn_type, bidirectional=bi)  # We have no interest in the network outputting the padding symbol\n",
        "    model.fit(train_dataset)\n",
        "    table[feature].append(round(model.score(test_dataset), 2))\n",
        "\n",
        "df = pd.DataFrame(table, index=languages.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3S2GUv19dA9",
        "outputId": "fbd3604f-861d-4c1c-a99f-6d26a2f6eee3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelling Vietnamese with Baseline...\n",
            "Modelling Vietnamese with GRU...\n",
            "Modelling Vietnamese with bi-LSTM...\n",
            "Modelling Vietnamese with bi-GRU...\n",
            "Modelling English with Baseline...\n",
            "Modelling English with GRU...\n",
            "Modelling English with bi-LSTM...\n",
            "Modelling English with bi-GRU...\n",
            "Modelling Finnish with Baseline...\n",
            "Modelling Finnish with GRU...\n",
            "Modelling Finnish with bi-LSTM...\n",
            "Modelling Finnish with bi-GRU...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define figure and axes\n",
        "fig, ax = plt.subplots(figsize=(6, 2))\n",
        "#hide the axes\n",
        "fig.patch.set_visible(False)\n",
        "ax.axis('off')\n",
        "ax.axis('tight')\n",
        "\n",
        "#create table\n",
        "binary_table = ax.table(cellText=df.values, rowLabels=df.index, colLabels=df.columns, loc='center')\n",
        "\n",
        "# bold results that are better than our basline\n",
        "for i, c in enumerate(df):\n",
        "  for j, v in enumerate(df[c]):\n",
        "    if v > df['Baseline'][j]:\n",
        "      binary_table[(j+1, i)].get_text().set_weight('bold') # SET FONT\n",
        "\n",
        "#display table\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "4gM24Bu-Kb1V",
        "outputId": "2374598b-b2b4-4e36-df3d-e2bb813d936b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x144 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bolded scores are better performers compared to the basline. As shown above, a bi-GRU model shows a better performance overall (although it is sometimes  on par with bi-LSTM for English and Finnish after several runs). \n",
        "The benefit of bidirectionality is the clearest with Vietnamese. It may be because morphologically poor (or analytic) languages rely more heavily on particles and word order instead of inflections to determine word classes, and bidirectional information gives us a stronger hint on word order.\n",
        "\n",
        "Let's use that to look at universal and language specific tags."
      ],
      "metadata": {
        "id": "gsmp1k8GTDDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "languages = {'vi': 'Vietnamese', 'en': 'English', 'fi': 'Finnish'}\n",
        "pos_table = defaultdict(list)\n",
        "\n",
        "for language in languages:\n",
        "  for pos in ('upos','xpos'):\n",
        "    print(f'Tagging {languages[language]} with {pos}...')\n",
        "    train_dataset = UDDataset(language, 'train', pos=pos)\n",
        "    test_dataset = UDDataset(language, 'test', pos=pos)\n",
        "    token2idx, tag2idx, idx2token, idx2tag = lut(train_dataset.X, train_dataset.y)\n",
        "    model = Tagger(word_embedding_dim=32,                                              \n",
        "                      hidden_dim=64,                                                 \n",
        "                      vocabulary_size=len(token2idx),                                  \n",
        "                      tagset_size=len(tag2idx)-1, lstm_gru='GRU', bidirectional=True)   \n",
        "    model.fit(train_dataset)\n",
        "    index = int(len(model.training_accuracy_)*(5/model.epochs))-1\n",
        "    pos_table[pos].append(round(model.score(test_dataset), 2))\n",
        "\n",
        "pos_df = pd.DataFrame(pos_table, index=languages.values())\n",
        "print(pos_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qvcbi0RUoFk",
        "outputId": "cf0f379f-5f6e-477c-995b-1933eabb517a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tagging Vietnamese with upos...\n",
            "Tagging Vietnamese with xpos...\n",
            "Tagging English with upos...\n",
            "Tagging English with xpos...\n",
            "Tagging Finnish with upos...\n",
            "Tagging Finnish with xpos...\n",
            "             upos   xpos\n",
            "Vietnamese  73.38  66.58\n",
            "English     89.19  85.93\n",
            "Finnish     75.85  87.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy for Vietnamese is higher with universal tags, while that for Finnish is higher with language specific tags. For English, using universal tags has a higher accuracy, but over several runs the accuracy of using the two sets of tags are similar.\n",
        "We can speculate that since morphologically rich languages like Finnish store more complex grammatical information in a word, it is helpful to establish more intricate POS tags that more accurately describe the grammatical roles in words, and tagging with such tags will yield a higher accuracy.\n",
        "\n",
        "Let's look at how the number of dimensions can affect our results. We vary the word embedding or hidden dimensions between 32 and 64, so we get a set of 4 results per language."
      ],
      "metadata": {
        "id": "eLs3LwPbfg9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "languages = {'vi': 'Vietnamese', 'en': 'English', 'fi': 'Finnish'}\n",
        "# dim_results = {'word embedding dimensions': {}, 'hidden dimensions': {}}\n",
        "dims = [32, 64]\n",
        "for language in languages:\n",
        "  for i in dims:\n",
        "    for j in dims:\n",
        "      print(f'Tagging {languages[language]} with {i} word embedding dimensions & {j} hidden dimensions...')\n",
        "      train_dataset = UDDataset(language, 'train')\n",
        "      test_dataset = UDDataset(language, 'test')\n",
        "      token2idx, tag2idx, idx2token, idx2tag = lut(train_dataset.X, train_dataset.y)\n",
        "      model = Tagger(word_embedding_dim=i,                                              \n",
        "                        hidden_dim=j,                                                 \n",
        "                        vocabulary_size=len(token2idx),                                  \n",
        "                        tagset_size=len(tag2idx)-1, lstm_gru='GRU', bidirectional=True)   \n",
        "      model.fit(train_dataset)\n",
        "      print(round(model.score(test_dataset), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmE2EJw7fo_7",
        "outputId": "f430526e-ae22-4e1f-89a7-b6a9c8ee4599"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tagging Vietnamese with 32 word embedding dimensions & 32 hidden dimensions...\n",
            "72.0\n",
            "Tagging Vietnamese with 32 word embedding dimensions & 64 hidden dimensions...\n",
            "71.75\n",
            "Tagging Vietnamese with 64 word embedding dimensions & 32 hidden dimensions...\n",
            "68.54\n",
            "Tagging Vietnamese with 64 word embedding dimensions & 64 hidden dimensions...\n",
            "75.21\n",
            "Tagging English with 32 word embedding dimensions & 32 hidden dimensions...\n",
            "84.98\n",
            "Tagging English with 32 word embedding dimensions & 64 hidden dimensions...\n",
            "87.51\n",
            "Tagging English with 64 word embedding dimensions & 32 hidden dimensions...\n",
            "88.85\n",
            "Tagging English with 64 word embedding dimensions & 64 hidden dimensions...\n",
            "89.81\n",
            "Tagging Finnish with 32 word embedding dimensions & 32 hidden dimensions...\n",
            "70.14\n",
            "Tagging Finnish with 32 word embedding dimensions & 64 hidden dimensions...\n",
            "78.9\n",
            "Tagging Finnish with 64 word embedding dimensions & 32 hidden dimensions...\n",
            "75.66\n",
            "Tagging Finnish with 64 word embedding dimensions & 64 hidden dimensions...\n",
            "84.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is obvious that a higher number of dimensions increases our POS tagging accuracy, but the impact is the strongest in Finnish (70.14% -> 84.33%) compared to Vietnamese (72.0% -> 75.21%) and English (84.98% -> 89.81%). This trend indicates that having more dimensions are especially helpful for tagging morphologically rich languages. It is also interesting to see that  increasing only either of the word embedding dimensions or the hidden dimensions are not conducive at all."
      ],
      "metadata": {
        "id": "E_Omblo11JDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comments\n",
        "\n",
        "Given the code for the tagger, implementing GRU, bidirectionality and other things are relatively straightforward. It is interesting to see how structures in our neural network can significantly affect performance for language tasks (POS tagging in this case), and that the impact has a clear trend across morphological richness. \n",
        "\n",
        "It was a bit challenging to start working on this assignment in the beginning, since this is the first time we use PyTorch, and implementing the `Dataset` and `Dataloader` and putting the padding and encoding process took a while before getting used to it."
      ],
      "metadata": {
        "id": "JjhxZz-zS3wp"
      }
    }
  ]
}